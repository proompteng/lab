model = "gpt-5.3-codex"
model_reasoning_summary = "detailed"
model_reasoning_effort = "high"
model_verbosity = "medium"
# Keep compaction proactive for long-running OpenWebUI sessions while staying well below model context limits.
model_auto_compact_token_limit = 24000
approval_policy = "never"
sandbox_mode = "danger-full-access"
suppress_unstable_features_warning = true

[features]
undo = true
web_search_request = true
web_search_cached = true
enable_request_compression = true
apply_patch_freeform = true
unified_exec = true
shell_snapshot = true
steer = true
collab = true
child_agents_md = true
collaboration_modes = false
responses_websockets = false

[mcp_servers.memories]
url = "http://127.0.0.1:8080/mcp"

[shell_environment_policy]
ignore_default_excludes = true

[projects."/workspace/lab"]
trust_level = "trusted"

[projects."/root"]
trust_level = "trusted"

[otel]
log_user_prompt = true
exporter = { otlp-http = { endpoint = "http://jangar-alloy.jangar.svc.cluster.local:4318/v1/logs", protocol = "binary" } }
