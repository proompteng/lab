apiVersion: v1
kind: ConfigMap
metadata:
  name: graf-mimir-rules
  namespace: observability
data:
  graf-rules.yaml: |
    groups:
      - name: graf-telemetry.rules
        rules:
          - alert: GrafHigh5xxRate
            expr: |
              sum(rate(graf_http_server_requests_count{http_status_code=~"5.."}[5m])) /
              clamp_min(sum(rate(graf_http_server_requests_count[5m])), 1) > 0.05
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Graf API is returning >5% 5xx responses
              description: Graf is emitting more than 5% 5xx errors over the last 5 minutes.
          - alert: GrafServiceDown
            expr: up{job="graf"} == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Graf service is unreachable
              description: The graf job is not reporting metrics (up metric is 0) for 5 minutes.
          - alert: GrafNoRequests
            expr: sum(rate(graf_http_server_requests_count[5m])) < 0.01
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Graf has not processed any requests
              description: The Graf HTTP counter has not incremented in the last 10 minutes.
      - name: codex-judge-pipeline.rules
        rules:
          - alert: CodexEventBusNoWorkflowCompletions
            expr: sum(changes({__name__=~"(nats|jetstream)_stream_last_seq", stream_name="default"}[15m])) == 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: Argo Events EventBus has no workflow completion messages
              description: No new JetStream messages landed in the Argo Events default stream for 15 minutes.
          - alert: CodexEventBusJetStreamDisabled
            expr: max({__name__=~"(nats|jetstream)_server_jetstream_disabled", cluster="default"}) == 1
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Argo Events EventBus JetStream is disabled
              description: JetStream reports disabled on the EventBus NATS cluster, blocking workflow completion delivery.
      - name: codex-pipeline-observability.rules
        rules:
          - alert: CodexKafkaCompletionsLagHigh
            expr: sum(kafka_consumergroup_lag_sum{consumergroup="jangar-codex-completions", topic="argo.workflows.completions"}) > 1000
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: Kafka completions lag is elevated
              description: The Jangar consumer group is >1000 messages behind on argo.workflows.completions for 15 minutes.
          - alert: CodexNatsAgentCommsLagHigh
            expr: |
              max(
                jetstream_consumer_num_pending{consumer_name="jangar-agent-comms", stream_name="agent-comms"} or
                jetstream_consumer_num_pending{consumer="jangar-agent-comms", stream="agent-comms"}
              ) > 1000
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: NATS agent comms consumer lag is elevated
              description: The jangar-agent-comms JetStream consumer has >1000 pending messages for 15 minutes.
          - alert: CodexJangarAgentCommsStalled
            expr: |
              (
                sum(rate(jetstream_stream_last_seq{stream_name="agent-comms"}[10m])) or
                sum(rate(jetstream_stream_last_seq{stream="agent-comms"}[10m]))
              ) > 0
              and sum(rate(jangar_agent_comms_inserted_total[10m])) == 0
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Jangar agent comms ingestion stalled
              description: Agent comms are publishing, but Jangar has not inserted any messages in 10 minutes.
          - alert: CodexJangarSseErrorRate
            expr: sum(rate(jangar_sse_errors_total[10m])) > 0.05
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Jangar SSE error rate elevated
              description: SSE error responses exceed 0.05/sec for 10 minutes across Jangar streams.
      - name: torghut-clickhouse.guardrails.rules
        rules:
          - alert: TorghutClickHouseDiskFreeLowWarning
            expr: |
              torghut_clickhouse_guardrails_disk_free_ratio{
                namespace="torghut",
                service="torghut-clickhouse-guardrails-exporter"
              } < 0.15
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Torghut ClickHouse disk free < 15%
              description: |
                Torghut ClickHouse is below 15% free disk for 10 minutes.

                First safe action: pause TA writes to stop the retry storm and prevent disk exhaustion.
              runbook_url: docs/torghut/design-system/v1/operations-pause-ta-writes.md
          - alert: TorghutClickHouseDiskFreeLowCritical
            expr: |
              torghut_clickhouse_guardrails_disk_free_ratio{
                namespace="torghut",
                service="torghut-clickhouse-guardrails-exporter"
              } < 0.08
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Torghut ClickHouse disk free < 8%
              description: |
                Torghut ClickHouse is below 8% free disk for 5 minutes (imminent out-of-space risk).

                Stop the bleeding: immediately pause TA writes.
              runbook_url: docs/torghut/design-system/v1/operations-pause-ta-writes.md
          - alert: TorghutClickHouseReplicaReadOnly
            expr: |
              torghut_clickhouse_guardrails_any_replica_readonly{
                namespace="torghut",
                service="torghut-clickhouse-guardrails-exporter"
              } >= 1
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: Torghut ClickHouse replica is read-only
              description: |
                At least one Torghut ClickHouse replicated table reports read-only, which will cause TA JDBC writes to fail.

                Stop the bleeding: pause TA writes first, then follow replica recovery (SYSTEM RESTORE REPLICA).
              runbook_url: docs/torghut/design-system/v1/operations-clickhouse-replica-and-keeper.md
          - alert: TorghutClickHouseGuardrailsExporterDown
            expr: |
              up{
                job="torghut",
                namespace="torghut",
                service="torghut-clickhouse-guardrails-exporter"
              } == 0
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Torghut ClickHouse guardrails exporter is down
              description: Guardrails metrics are not being scraped, so disk/read-only alerts may not fire.
          - alert: TorghutClickHouseGuardrailsScrapeFailing
            expr: |
              torghut_clickhouse_guardrails_last_scrape_success{
                namespace="torghut",
                service="torghut-clickhouse-guardrails-exporter"
              } == 0
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Torghut ClickHouse guardrails scrape failing
              description: Guardrails exporter is up but cannot query ClickHouse successfully.
      - name: torghut-ws.rules
        rules:
          - alert: TorghutWSForwarderDown
            expr: |
              up{
                job="torghut",
                namespace="torghut",
                service="torghut-ws"
              } == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Torghut WS forwarder is down
              description: |
                torghut-ws is not being scraped (up=0) for 5 minutes. Market data will not flow into Kafka, and TA will stall.
              runbook_url: docs/torghut/design-system/v1/operations-ws-connection-limit-and-auth.md
          - alert: TorghutWSForwarderNotReady
            expr: |
              torghut_ws_readyz_status{
                namespace="torghut",
                service="torghut-ws"
              } == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Torghut WS forwarder not ready
              description: |
                torghut-ws /readyz is failing for 5 minutes (Alpaca/Kafka gates not healthy).
              runbook_url: docs/torghut/design-system/v1/operations-ws-connection-limit-and-auth.md
          - alert: TorghutWSKafkaSendErrors
            expr: |
              rate(
                torghut_ws_kafka_send_errors_total{
                  namespace="torghut",
                  service="torghut-ws"
                }[5m]
              ) > 0
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Torghut WS Kafka send errors
              description: torghut-ws is reporting Kafka send errors over the last 10 minutes.
          - alert: TorghutWSKafkaSendsStalledDuringMarketHours
            expr: |
              (
                sum(
                  rate(
                    torghut_ws_kafka_send_latency_seconds_count{
                      namespace="torghut",
                      service="torghut-ws"
                    }[5m]
                  )
                ) == bool 0
              )
              * on() group_left()
              (
                (day_of_week(vector(time())) >= bool 1)
                * (day_of_week(vector(time())) <= bool 5)
                * (hour(vector(time())) >= bool 14)
                * (hour(vector(time())) < bool 21)
              )
            for: 15m
            labels:
              severity: critical
            annotations:
              summary: Torghut WS is not publishing Kafka records (market hours)
              description: |
                torghut-ws has published 0 records/sec for 15 minutes during market hours (UTC schedule).

                This usually means the Alpaca WS isn't receiving events or subscriptions are broken.
              runbook_url: docs/torghut/design-system/v1/operations-ws-connection-limit-and-auth.md
      - name: torghut-ta.rules
        rules:
          - alert: TorghutTAJobmanagerDown
            expr: |
              up{
                job="torghut",
                namespace="torghut",
                service="torghut-ta"
              } == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Torghut TA jobmanager metrics endpoint is down
              description: TA jobmanager is not being scraped (up=0) for 5 minutes.
              runbook_url: docs/torghut/design-system/v1/operations-ta-replay-and-recovery.md
          - alert: TorghutTACheckpointsStalled
            expr: |
              (
                time()
                - max(
                  flink_jobmanager_job_lastCheckpointCompletedTimestamp{
                    namespace="torghut",
                    service="torghut-ta"
                  }
                ) / 1000
              ) > 180
            for: 10m
            labels:
              severity: critical
            annotations:
              summary: Torghut TA checkpoints appear stalled
              description: |
                Flink last checkpoint completed timestamp is older than 3 minutes for 10 minutes.
                This strongly indicates the TA job is stuck or failing to checkpoint.
              runbook_url: docs/torghut/design-system/v1/operations-ta-replay-and-recovery.md
      - name: torghut-trading.rules
        rules:
          - alert: TorghutTradingRevisionMetricsMissing
            expr: |
              absent(
                up{
                  job="torghut",
                  namespace="torghut",
                  service=~"torghut-[0-9]{5}-private"
                }
              ) == 1
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Torghut trading revision metrics missing
              description: |
                No active Knative private revision service metrics are being scraped for torghut.
                If torghut should be running, this may indicate revision readiness failures or scrape config drift.
              runbook_url: docs/torghut/design-system/v1/operations-knative-revision-failures.md
          - alert: TorghutTradingRevisionMetricsDown
            expr: |
              max(
                up{
                  job="torghut",
                  namespace="torghut",
                  service=~"torghut-[0-9]{5}-private"
                }
              ) == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Torghut trading revision metrics endpoint is down
              description: |
                The active Knative private revision for torghut is being scraped but up=0 for 5 minutes.
              runbook_url: docs/torghut/design-system/v1/operations-knative-revision-failures.md
	      - name: torghut-freshness.rules
	        rules:
	          - alert: TorghutSignalsStaleDuringMarketHours
	            expr: |
	              (
	                time()
	                - max(
	                  torghut_clickhouse_guardrails_ta_signals_max_event_ts_seconds{
	                    namespace="torghut",
	                    service="torghut-clickhouse-guardrails-exporter"
	                  }
	                )
	              ) > bool 900
	              * on() group_left()
	              (
	                (day_of_week(vector(time())) >= bool 1)
	                * (day_of_week(vector(time())) <= bool 5)
	                * (hour(vector(time())) >= bool 14)
	                * (hour(vector(time())) < bool 21)
	              )
	            for: 15m
	            labels:
	              severity: critical
	            annotations:
              summary: Torghut signals are stale (market hours)
              description: |
                ClickHouse ta_signals max(event_ts) is older than 15 minutes during market hours (UTC schedule).

                First checks:
                - torghut-ws readiness and Kafka publishing
                - torghut-ta checkpointing and ClickHouse JDBC sink health
              runbook_url: docs/torghut/design-system/v1/operations-ta-replay-and-recovery.md
	          - alert: TorghutMicrobarsStaleDuringMarketHours
	            expr: |
	              (
	                time()
	                - max(
	                  torghut_clickhouse_guardrails_ta_microbars_max_window_end_seconds{
	                    namespace="torghut",
	                    service="torghut-clickhouse-guardrails-exporter"
	                  }
	                )
	              ) > bool 300
	              * on() group_left()
	              (
	                (day_of_week(vector(time())) >= bool 1)
	                * (day_of_week(vector(time())) <= bool 5)
	                * (hour(vector(time())) >= bool 14)
	                * (hour(vector(time())) < bool 21)
	              )
	            for: 10m
	            labels:
	              severity: warning
	            annotations:
              summary: Torghut microbars are stale (market hours)
              description: |
                ClickHouse ta_microbars max(window_end) is older than 5 minutes during market hours (UTC schedule).
              runbook_url: docs/torghut/design-system/v1/operations-ta-replay-and-recovery.md
