apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: jangar-memory-op
  namespace: argo-workflows
spec:
  serviceAccountName: codex-workflow
  entrypoint: run
  templates:
    - name: run
      inputs:
        parameters:
          - name: memoryRef
            default: ''
          - name: operation
            default: ''
          - name: payload
            default: ''
          - name: namespace
            default: ''
      script:
        image: registry.ide-newton.ts.net/lab/jangar:latest
        env:
          - name: GITHUB_TOKEN
            valueFrom:
              secretKeyRef:
                name: github-token
                key: token
        command:
          - /bin/bash
          - -c
        source: |
          set -euo pipefail
          memory_ref="{{inputs.parameters.memoryRef}}"
          operation="{{inputs.parameters.operation}}"
          payload="{{inputs.parameters.payload}}"
          namespace="{{inputs.parameters.namespace}}"
          if [ -z "${namespace}" ]; then
            namespace="$(kubectl get workflow {{workflow.name}} -n {{workflow.namespace}} -o jsonpath='{.metadata.labels.crossplane\\.io/claim-namespace}' 2>/dev/null || true)"
          fi
          if [ -z "${namespace}" ]; then
            namespace="{{workflow.namespace}}"
          fi

          if [ -z "${memory_ref}" ]; then
            echo "memoryRef is required" >&2
            exit 1
          fi

          if [[ "${memory_ref}" == */* ]]; then
            memory_namespace="${memory_ref%%/*}"
            memory_name="${memory_ref##*/}"
          else
            memory_namespace="${namespace}"
            memory_name="${memory_ref}"
          fi

          spec_schema="$(kubectl get memories.memory.proompteng.ai "${memory_name}" -n "${memory_namespace}" -o jsonpath='{.spec.dataset.schema}' 2>/dev/null || true)"
          dataset="$(kubectl get memories.memory.proompteng.ai "${memory_name}" -n "${memory_namespace}" -o jsonpath='{.spec.dataset.name}' 2>/dev/null || true)"
          status_schema="$(kubectl get memories.memory.proompteng.ai "${memory_name}" -n "${memory_namespace}" -o jsonpath='{.status.schema}' 2>/dev/null || true)"
          embedding_dim="$(kubectl get memories.memory.proompteng.ai "${memory_name}" -n "${memory_namespace}" -o jsonpath='{.spec.embeddings.dimension}' 2>/dev/null || true)"
          secret_name="$(kubectl get memories.memory.proompteng.ai "${memory_name}" -n "${memory_namespace}" -o jsonpath='{.status.connectionSecretRef.name}' 2>/dev/null || true)"
          secret_namespace="$(kubectl get memories.memory.proompteng.ai "${memory_name}" -n "${memory_namespace}" -o jsonpath='{.status.connectionSecretRef.namespace}' 2>/dev/null || true)"
          if [ -z "${secret_namespace}" ]; then
            secret_namespace="${memory_namespace}"
          fi

          if [ -n "${spec_schema}" ] && [ -n "${status_schema}" ] && [ "${spec_schema}" != "${status_schema}" ]; then
            echo "memory schema mismatch: spec=${spec_schema} status=${status_schema}" >&2
            exit 1
          fi

          schema="${spec_schema:-${status_schema:-public}}"

          if [ -z "${secret_name}" ]; then
            echo "memory connectionSecretRef is not ready" >&2
            exit 1
          fi

          get_secret_field() {
            kubectl get secret "${secret_name}" -n "${secret_namespace}" -o "jsonpath={.data.$1}" 2>/dev/null | base64 -d 2>/dev/null || true
          }

          db_uri="$(get_secret_field uri)"
          endpoint="$(get_secret_field endpoint)"
          if [ -z "${endpoint}" ]; then
            endpoint="$(get_secret_field host)"
          fi
          db_name="$(get_secret_field database)"
          if [ -z "${db_name}" ]; then
            db_name="$(get_secret_field dbname)"
          fi
          db_user="$(get_secret_field username)"
          if [ -z "${db_user}" ]; then
            db_user="$(get_secret_field user)"
          fi
          db_pass="$(get_secret_field password)"

          if [ -z "${db_uri}" ]; then
            if [ -z "${endpoint}" ] || [ -z "${db_name}" ] || [ -z "${db_user}" ] || [ -z "${db_pass}" ]; then
              echo "connection secret missing database fields" >&2
              exit 1
            fi
            db_user_escaped="$(bun -e 'console.log(encodeURIComponent(process.argv[1] ?? ""))' "${db_user}")"
            db_pass_escaped="$(bun -e 'console.log(encodeURIComponent(process.argv[1] ?? ""))' "${db_pass}")"
            db_uri="postgresql://${db_user_escaped}:${db_pass_escaped}@${endpoint}/${db_name}"
          fi

          if [[ "${db_uri}" != *"sslmode="* ]]; then
            if [[ "${db_uri}" == *"?"* ]]; then
              db_uri="${db_uri}&sslmode=require"
            else
              db_uri="${db_uri}?sslmode=require"
            fi
          fi

          payload_b64="$(printf '%s' "${payload}" | base64 -w0)"

          export NODE_PATH="/app/node_modules"
          export DB_URI="${db_uri}"
          export DB_SCHEMA="${schema}"
          export DATASET="${dataset:-${memory_name}}"
          export OPERATION="${operation}"
          export PAYLOAD_B64="${payload_b64}"
          export EMBEDDING_DIM="${embedding_dim:-1536}"

          cat <<'NODE' > /tmp/jangar-memory-op.mjs
          import { createHash } from 'node:crypto'
          import { Pool } from 'pg'

          const schema = process.env.DB_SCHEMA || 'public'
          if (!/^[a-zA-Z0-9_]+$/.test(schema)) {
            throw new Error(`invalid schema: ${schema}`)
          }
          const dataset = process.env.DATASET || ''
          if (!dataset) {
            throw new Error('dataset is required')
          }
          const operation = process.env.OPERATION || 'event'
          const payloadRaw = Buffer.from(process.env.PAYLOAD_B64 || '', 'base64').toString('utf8')
          let payload = {}
          if (payloadRaw) {
            try {
              payload = JSON.parse(payloadRaw)
            } catch {
              payload = { raw: payloadRaw }
            }
          }

          const dimension = Number.parseInt(process.env.EMBEDDING_DIM || '1536', 10)
          const getEmbedding = (text) => {
            const hash = createHash('sha256').update(text).digest()
            const vector = new Array(dimension)
            for (let i = 0; i < dimension; i += 1) {
              const idx = i % hash.length
              vector[i] = (hash[idx] / 255) * 2 - 1
            }
            return vector
          }
          const vectorToPg = (vector) => `[${vector.join(',')}]`
          const pool = new Pool({ connectionString: process.env.DB_URI, ssl: { rejectUnauthorized: false } })
          const key = payload.key || payload.id || `${operation}-${Date.now()}`
          const text = payload.text || payload.content || payload.summary || JSON.stringify(payload)

          await pool.query(
            `INSERT INTO ${schema}.memory_events (dataset, event_type, payload) VALUES ($1, $2, $3)`,
            [dataset, operation, payload],
          )

          if (operation.toLowerCase().includes('kv') || payload.type === 'kv') {
            const kvValue = payload.value ?? payload
            await pool.query(
              `INSERT INTO ${schema}.memory_kv (dataset, key, value)
               VALUES ($1, $2, $3)
               ON CONFLICT (dataset, key)
               DO UPDATE SET value = EXCLUDED.value, updated_at = now()`,
              [dataset, key, kvValue],
            )
          }

          if (operation.toLowerCase().includes('embed') || payload.embedding || text) {
            const embedding = Array.isArray(payload.embedding) ? payload.embedding : getEmbedding(text)
            const vector = vectorToPg(embedding)
            await pool.query(
              `INSERT INTO ${schema}.memory_embeddings (dataset, key, embedding, metadata)
               VALUES ($1, $2, $3::vector, $4)`,
              [dataset, key, vector, payload.metadata ?? {}],
            )
          }

          await pool.end()
          NODE

          bun /tmp/jangar-memory-op.mjs
