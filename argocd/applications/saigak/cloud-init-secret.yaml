apiVersion: v1
kind: Secret
metadata:
  name: saigak-cloud-init
type: Opaque
stringData:
  userdata: |-
    #cloud-config
    preserve_hostname: false
    hostname: saigak
    manage_etc_hosts: true
    package_update: true
    package_upgrade: false
    disk_setup:
      /dev/vdb:
        table_type: gpt
        layout: true
        overwrite: false
    fs_setup:
      - device: /dev/vdb1
        filesystem: ext4
        overwrite: false
    mounts:
      - ["/dev/vdb1", "/var/lib/ollama", "ext4", "defaults,nofail", "0", "2"]
    packages:
      - openssh-server
      - ca-certificates
      - curl
      - git
      - jq
      - gnupg
      - cuda-drivers
    write_files:
      - path: /etc/systemd/system/ollama.service.d/99-saigak.conf
        owner: root:root
        permissions: '0644'
        content: |-
          [Service]
          Environment="OLLAMA_HOST=0.0.0.0:11434"
          Environment="OLLAMA_MODELS=/var/lib/ollama"
      - path: /etc/saigak/qwen3-embedding-0-6b.modelfile
        owner: root:root
        permissions: '0644'
        content: |-
          FROM qwen3-embedding:0.6b
          TEMPLATE {{ .Prompt }}
          PARAMETER num_ctx 4096
    users:
      - name: ubuntu
        groups: [sudo]
        shell: /bin/bash
        sudo: ALL=(ALL) NOPASSWD:ALL
        ssh_authorized_keys:
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOE//lpGZI2015yMUjHwhWJjgarTLIsqQBIFXlAanPvS
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIDVYPSSdt6tjSWRooRm7nUDS73CebsP92G6GjFa9X+zy
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAzVze3nx4QPa6t9Wvp5FLrcAlM7BDLUmxf049N4HC6d
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIDW2gOD2bqZxDwKEsfZM+ggSBV+DlTrUxMQY8JxDMVgG
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAlmf/vteEu7gLBfxyEUjVtQiZ2LCqU6zo+6+G5gmaaa
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEht47QYSXM1n78ww4Aw9jHS50FR9IpQlQGU8emLg1ed
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIB9gANXCk/KnE27qvzZk9pGSc1wIzSUewHhqZQXwFJs+
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAINXAA7B1vTdTvaMTUcDJTD96v1oiNZx6XI+amVwPXPzy
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOco184B4eZEOoLP5ehTK9cgsJgbelKWUxXuO3+S38U/
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAII0/89LwFLAM6tu2gtbwVDrQwFhPiW55RciZo0RUVMrF
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIH77X+Ekaz8sSLPImUYO8VYhgDDcb+DXkqU26UZ2PaAP
          - ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBMqGcgm6U9z2d9kH5SNjm4wZumlbMxndFi40iNEhI2OKvfSoE4OQJQ8j5KCiu6GrcE2biJcqP1dkMCaJ8xcaYA8= sshid.io/gregkonush
    ssh_pwauth: false
    disable_root: true
    runcmd:
      - [ bash, -lc, 'systemctl enable --now ssh' ]
      - [ bash, -lc, 'for i in $(seq 1 60); do if nvidia-smi -L; then break; fi; sleep 2; done; nvidia-smi -L || echo \"warning: nvidia-smi not ready yet\" >&2' ]
      - [ bash, -lc, 'curl -fsSL https://ollama.com/install.sh | sh' ]
      - [ bash, -lc, 'systemctl stop ollama || true' ]
      - [ bash, -lc, 'mkdir -p /etc/systemd/system/ollama.service.d' ]
      - [ bash, -lc, 'id ollama >/dev/null 2>&1 && chown -R ollama:ollama /var/lib/ollama || true' ]
      - [ bash, -lc, 'systemctl daemon-reload' ]
      - [ bash, -lc, 'systemctl enable --now ollama' ]
      - [ bash, -lc, 'sleep 2' ]
      - [ bash, -lc, 'curl -fsS http://127.0.0.1:11434/api/version' ]
      - [ bash, -lc, 'ollama pull qwen3-embedding:0.6b' ]
      - [ bash, -lc, 'ollama create qwen3-embedding-saigak:0.6b -f /etc/saigak/qwen3-embedding-0-6b.modelfile' ]
      - [ bash, -lc, 'ollama list | awk \"{print \\$1}\" | grep -Fxq \"qwen3-embedding-saigak:0.6b\"' ]
